# Ray Data + vLLM Batch Inference Test Dependencies
ray[data]==2.49.1
vllm==0.10.0
torch>=2.0.0
transformers>=4.30.0
datasets>=2.10.0
pyyaml>=6.0
pytest>=7.0.0
pytest-mock>=3.10.0
requests>=2.28.0