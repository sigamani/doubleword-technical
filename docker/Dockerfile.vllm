FROM vllm/vllm-openai:v0.10.0

WORKDIR /app

# Install huggingface_hub and download model
RUN pip install --no-cache-dir huggingface_hub

RUN mkdir -p /app/models && \
    curl -LsSf https://hf.co/cli/install.sh | bash && \
    export PATH="/root/.local/bin:$PATH" && \
    hf download Qwen/Qwen2.5-0.5B-Instruct --local-dir /app/models/Qwen2.5-0.5B-Instruct

COPY api/ ./api/
COPY pipeline/ ./pipeline/
COPY config.py ./

RUN useradd -m -u 1000 appuser && \
    chown -R appuser:appuser /app

USER appuser

EXPOSE 8001

# Use the default entrypoint from the base image, just override the command
CMD ["--model", "/app/models/Qwen2.5-0.5B-Instruct", "--host", "0.0.0.0", "--port", "8001", "--max-model-len", "2048", "--gpu-memory-utilization", "0.8"]