# vLLM Model Configuration
model_name: "Qwen/Qwen2.5-0.5B-Instruct"
max_model_len: 512
enforce_eager: true
dtype: "half"
gpu_memory_utilization: 0.90
tensor_parallel_size: 1

# Generation parameters
max_tokens: 256
temperature: 0.7
top_p: 0.9
frequency_penalty: 0.0
presence_penalty: 0.0

# Batch processing
batch_size: 32
concurrency: 2